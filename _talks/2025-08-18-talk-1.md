---
title: "Towards No-Code Programming of Cobots: Experiments with Code Synthesis by Large Code Models for Conversational Programming"
collection: talks
permalink: /talks/2025-08-18-talk-1
date: 2025-08-18
type: "Talk"
venue: "RO-MAN Workshop"
image_sliders:
  - slider1
---

### Presented at [Towards No-Code Programming of Cobots: Experiments with Code Synthesis by Large Code Models for Conversational Programming](https://arxiv.org/pdf/2409.11041) paper at [1st Workshop on Interactive Task Learning in Human-Robot co-construction (ITL4HRI) at RO-MAN 2025](https://ease-crc.org/1st-workshop-on-interactive-task-learning-in-human-robot-co-construction-itl4hri/)


While there has been a lot of research recently on robots in household environments, at the present time, most
robots in existence can be found on shop floors, and most interactions between humans and robots happen
there. “Collaborative robots” (cobots) designed to work alongside humans on assembly lines traditionally require
expert programming, limiting ability to make changes, or manual guidance, limiting expressivity of the resulting
programs. To address these limitations, we explore using Large Language Models (LLMs), and in particular, their
abilities of doing in-context learning, for conversational code generation. As a first step, we define SARTCo,
the “ Spatial Arrangement and Reconstruction Tasks for Cobots ”, a 2.5D structure building task designed to
lay the foundation for simulating industry assembly scenarios. In this task, a ‘programmer’ instructs a cobot,
using natural language, on how a certain assembly is to be built; that is, the programmer induces a program,
through natural language. We create a dataset that pairs target structures with various example instructions
(human-authored, template-based, and model-generated) and example code. With this, we systematically evaluate
the capabilities of state-of-the-art LLMs for synthesising this kind of code, given in-context examples. Evaluating
in a simulated environment, we find that LLMs are capable of generating accurate ‘first order code’ (instruction
sequences), but have problems producing ‘higher-order code’ (abstractions such as functions, or use of loops).

[Paper](https://arxiv.org/pdf/2409.11041)